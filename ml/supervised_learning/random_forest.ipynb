{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/lality/projects/personal/ML_Algo/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.supervised_learning import DecisionTreeClassifier\n",
    "from ml.tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(y):\n",
    "    log2 = lambda x: math.log(x) / math.log(2)\n",
    "    unique_labels = np.unique(y)\n",
    "    entropy = 0\n",
    "    for label in unique_labels:\n",
    "        count = len(y[y == label])\n",
    "        p = count / len(y)\n",
    "        entropy += -p * log2(p)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_on_feature(X, feature_i, threshold):\n",
    "    split_func = None\n",
    "    if isinstance(threshold, int) or isinstance(threshold, float):\n",
    "        split_func = lambda sample: sample[feature_i] >= threshold\n",
    "    else:\n",
    "        split_func = lambda sample: sample[feature_i] == threshold\n",
    "    \n",
    "    X_1 = np.array([sample for sample in X if split_func(sample)])\n",
    "    X_2 = np.array([sample for sample in X if not split_func(sample)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_subsets(X, y, n_subsets, replacement=True):\n",
    "    n_samples = np.shape(X)[0]\n",
    "    Xy = np.concatenate((X, y.reshape((1, len(y))).T), axis=1)\n",
    "    np.random.shuffle(Xy)\n",
    "    subsets = []\n",
    "    \n",
    "    subsample_size = int(n_samples // 2)\n",
    "    if replacement:\n",
    "        subsample_size = n_samples\n",
    "    \n",
    "    for _ in rnage(n_subsets):\n",
    "        idx = np.random.choice(range(n_samples), size=np.shape(range(subsample_size)), replace=replacement)\n",
    "        X = Xy[idx][:, :-1]\n",
    "        y = Xy[idx][:, -1]\n",
    "        subsets.append([X, y])\n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, min_samples_split=2, min_impurity=1e-7, max_depth=None, loss=None):\n",
    "        self.root = None\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_impurity = min_impurity\n",
    "        self.max_depth = max_depth if max_depth else float('inf')\n",
    "        self._impurity_calculation = None\n",
    "        self._leaf_value_calculation = None\n",
    "        self.one_dim = None\n",
    "        self.loss = loss\n",
    "    \n",
    "    def fit(self, X, y, loss):\n",
    "        self.one_dim = len(np.shape(y)) == 1\n",
    "        self.root = self._build_tree(X, y)\n",
    "        self.loss=None\n",
    "        \n",
    "    def _build_tree(self, X, y, current_depth=0):\n",
    "        largest_impurity = 0\n",
    "        best_criteria = None\n",
    "        best_sets = None\n",
    "        if len(np.shape(y)) == 1:\n",
    "            y = np.expand_dims(y, axis=1)\n",
    "        Xy = np.concatenate((X, y), axis=1)\n",
    "        \n",
    "        n_samples, n_features = np.shape(X)\n",
    "        \n",
    "        if n_samples >= self.min_samples_split and current_depth <= self.max_depth:\n",
    "            for feature_i in range(n_features):\n",
    "                feature_values = np.expand_dims(X[:, feature_i], axis=1)\n",
    "                unique_values = np.unique(feature_values)\n",
    "                \n",
    "                for threshold in unique_values:\n",
    "                    Xy1, Xy2 = divide_on_feature(Xy, feature_i, threshold)\n",
    "                    if len(Xy1) > 0 and len(Xy2) > 0:\n",
    "                        y1 = Xy1[:, n_features:]\n",
    "                        y2 = Xy2[:, n_features:]\n",
    "                        \n",
    "                        impurity = self._impurity_calculation(y, y1, y2)\n",
    "                        \n",
    "                        if impurity > largest_impurity:\n",
    "                            largest_impurity = impurity\n",
    "                            best_criteria = {\"feature_i\": feature_i, \"threshold\": threshold}\n",
    "                            best_sets = {\n",
    "                                \"leftX\": Xy1[:, :n_features],   # X of left subtree\n",
    "                                \"lefty\": Xy1[:, n_features:],   # y of left subtree\n",
    "                                \"rightX\": Xy2[:, :n_features],  # X of right subtree\n",
    "                                \"righty\": Xy2[:, n_features:]   # y of right subtree\n",
    "                                }\n",
    "        if largest_impurity > self.min_impurity:\n",
    "            true_branch = self._build_tree(best_sets[\"leftX\"], best_sets[\"lefty\"], current_depth + 1)\n",
    "            false_branch = self._build_tree(best_sets[\"rightX\"], best_sets[\"righty\"], current_depth + 1)\n",
    "            return DecisionNode(feature_i=best_criteria[\"feature_i\"], threshold=best_criteria[\"threshold\"], true_branch=true_branch, false_branch=false_branch)\n",
    "        \n",
    "        leaf_value = self._leaf_value_calculation(y)\n",
    "        return DecisionNode(value=leaf_value)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = [self.predict_value(sample) for sample in X]\n",
    "        return y_pred\n",
    "    \n",
    "    def predict_value(self, x, tree=None):\n",
    "        if tree is None:\n",
    "            tree = self.root\n",
    "        \n",
    "        if tree.value is not None:\n",
    "            return tree.value\n",
    "        \n",
    "        feature_value = x[tree.feature_i]\n",
    "        \n",
    "        branch = tree.false_branch\n",
    "        if isinstance(feature_value, int) or isinstance(feature_value, float):\n",
    "            if feature_value >= tree.threshold:\n",
    "                branch = tree.true_branch\n",
    "        elif feature_value == tree.threshold:\n",
    "            branch = tree.true_branch\n",
    "        \n",
    "        return self.predict_value(x, branch)\n",
    "    \n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "        else:\n",
    "            print(\"%s:%s? \" % (tree.feature_i, tree.threshold))\n",
    "            print(\"%sT->\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.true_branch, indent + indent)\n",
    "            self.print_tree(tree.false_branch, indent + indent)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationTree(DecisionTree):\n",
    "    def _calulate_information_gain(self, y, y1, y2):\n",
    "        p = len(y1) / len(y)\n",
    "        entropy = calculate_entropy(y)\n",
    "        info_gain = entropy - p * calculate_entropy(y1) - (1 - p) * calculate_entropy(y2)\n",
    "        return info_gain\n",
    "    \n",
    "    def _majority_vote(self, y):\n",
    "        most_common = None\n",
    "        max_count = 0\n",
    "        for label in np.unique(y):\n",
    "            count = len(y[y == label])\n",
    "            if count > max_count:\n",
    "                most_common = label\n",
    "                max_count = count\n",
    "        return most_common\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self._impurity_calculation = self._calculate_information_gain\n",
    "        self._leaf_value_calculation = self._majority_vote\n",
    "        super(ClassificationTree, self).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=100, max_features=None, min_samples_split=2, min_gain=0, max_depth=float('inf')):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = max_features\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_gain = min_gain\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "        \n",
    "        for _ in range(n_estimators):\n",
    "            self.tree.append(\n",
    "                ClassificationTree(min_samples_split=self.min_samples_split, \n",
    "                                   min_impurity=self.min_gain, \n",
    "                                   max_depth=self.max_depth)\n",
    "            )\n",
    "        \n",
    "        def fit(self, X, y):\n",
    "            n_features = np.shape(X)[1]\n",
    "            if not self.max_features:\n",
    "                self.max_features = int(math.sqrt(n_features))\n",
    "            \n",
    "            subsets = get_random_subsets(X, y, self.n_features)\n",
    "            \n",
    "            for i in range(self.n_estimators):\n",
    "                X_subset, y_subset = subsets[i]\n",
    "                idx = np.random.choice(range(n_features), size=self.max_features, replace=True)\n",
    "                self.tress[i].feature_indices = idx\n",
    "                X_subset = X_subset[:, idx]\n",
    "                self.trees[i].fit(X_subset, y_subset)\n",
    "        \n",
    "        def predict(self, X):\n",
    "            y_preds = np.empty((X.shape[0], len(self.trees)))\n",
    "            for i, tree in enumerate(self.trees):\n",
    "                idx = tree.feature_indices\n",
    "                prediction = tree.predict(X[:, idx])\n",
    "                y_preds[:, i] = prediction\n",
    "            y_pred = []\n",
    "            for sample_predictors in y_preds:\n",
    "                y_pred.append(np.bincount(sample_predictions.astype('int')).argmax())\n",
    "            return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:venv-2]",
   "language": "python",
   "name": "conda-env-venv-2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
